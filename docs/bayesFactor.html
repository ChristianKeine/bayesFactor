
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>bayesFactor</title><meta name="generator" content="MATLAB 9.5"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2018-12-21"><meta name="DC.source" content="bayesFactor.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#3">Default parameters for the Monte Carlo integration.</a></li><li><a href="#5">Public acces functions - the main interface</a></li><li><a href="#7">Setup sharing of priors as requested</a></li><li><a href="#8">Construct the design matrix for the main effects</a></li><li><a href="#9">Construct the interaction parts of the design matrix for all requested interactions</a></li><li><a href="#10">Assign groups of effects to use the same prior on effect size.</a></li><li><a href="#11">Call the anova function for the actual analysis</a></li><li><a href="#13">Internal computations.</a></li><li><a href="#15">Setup the PDF to do importance sampling</a></li><li><a href="#16">Evaluate the function at these g values</a></li><li><a href="#18">Helper functions</a></li><li><a href="#20">Follow  Rouder et al. 2012</a></li><li><a href="#22">Public User interface</a></li><li><a href="#23">Hide some of the handle class member functions for ease of use.</a></li></ul></div><pre class="codeinput"><span class="keyword">classdef</span> bayesFactor &lt; handle
</pre><pre class="codeinput">    <span class="comment">% A class to perform Bayes Factor statistical analysis to quantify</span>
    <span class="comment">% evidnce in favor or against a hypothesis.</span>
    <span class="comment">% For background see:</span>
    <span class="comment">%</span>
    <span class="comment">% The mathemetical underpinning for these routines is provided in</span>
    <span class="comment">%</span>
    <span class="comment">%</span>
    <span class="comment">% Implementation notes:</span>
    <span class="comment">%  The class currently does not store data, only some default parameers</span>
    <span class="comment">%  that are used in different contexts.</span>
    <span class="comment">% BK - 2018</span>

    properties (SetAccess = public, GetAccess =public)
</pre><h2 id="3">Default parameters for the Monte Carlo integration.</h2><pre class="codeinput">        minG = 0.0001;
        maxG = 10000;
        stepG = 0.05;
        nrSamples = 10000;
        nDimsForMC = 3; <span class="comment">% If there are this many dimensions, use MC integration</span>
        <span class="comment">% 1 and 2D integration work fine with standard</span>
        <span class="comment">% integral.m but 3d is slow and higher not</span>
        <span class="comment">% possible.</span>
</pre><pre class="codeinput">    <span class="keyword">end</span>
</pre><h2 id="5">Public acces functions - the main interface</h2><pre class="codeinput">    methods (Access=public)

        <span class="keyword">function</span> o = bayesFactor
            <span class="comment">% Constructor. Nothing to do.</span>

        <span class="keyword">end</span>

        <span class="keyword">function</span> [bf10,model,aov] = linearMixedModel(o,tbl,formula,varargin)
</pre><pre class="codeinput">            <span class="comment">% Analyze table data with a linear mixed effects model.</span>
            <span class="comment">%</span>
            <span class="comment">% INPUT</span>
            <span class="comment">% tbl = The table with data.</span>
            <span class="comment">% formula = The linear (mixed) model using Wilcoxon notation.</span>
            <span class="comment">%           See LinearModel and LinearMixedModel in the stats</span>
            <span class="comment">%           toolbox for definition</span>
            <span class="comment">% Parm/Value pairs:</span>
            <span class="comment">% 'sharedPriors' - Which columns (i.e. factors) in the table should share a</span>
            <span class="comment">%                   their prior on their effect size. The default is that</span>
            <span class="comment">%                   all levels within a factor share a prior.</span>
            <span class="comment">%                   To share priors across factors, use</span>
            <span class="comment">%                      {'{'a','b'},{'c','d'}}   -&gt; share priors for a and b</span>
            <span class="comment">%                       and, separately, for c and d.</span>
            <span class="comment">%                      {{'a','b','c','d'}} -&gt;  share priors for all factors</span>
            <span class="comment">%                      (this is the 'single g' approach in Rouder.</span>
            <span class="comment">%                      Shortcuts:</span>
            <span class="comment">%                       'within' - share within a fixed effect factor, not across</span>
            <span class="comment">%                       'singleG' - share across all fixed effects.</span>
            <span class="comment">% 'interactions'    - Include interactions ('all') or not ('none'). Default</span>
            <span class="comment">%                       is  'none'.  Or specify a set {'a:b','c:d'}</span>
            <span class="comment">%</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% bf10 - The Bayes Factor comparing the model to the model with intercept only.</span>
            <span class="comment">%       To compute BF for more refined hypotheses you compute</span>
            <span class="comment">%       a BF for the full model, and a restricted model and</span>
            <span class="comment">%       then take the ratio. See rouderFigures for examples.</span>
            <span class="comment">% model - A linear model or linear mixed model from the</span>
            <span class="comment">%           statistics toolbox</span>
            <span class="comment">% aov    - results of an ANOVA</span>
            <span class="comment">%</span>
            <span class="comment">% BK -2018</span>

            p=inputParser;
            p.addParameter(<span class="string">'interactions'</span>,<span class="string">'none'</span>,@(x) (ischar(x) || iscell(x)));
            p.addParameter(<span class="string">'sharedPriors'</span>,<span class="string">'within'</span>,@(x) ischar(x) || (iscell(x) &amp;&amp; iscell(x{1}))); <span class="comment">% Cell containing cells with factors(columns) that share a prior.</span>
            p.addParameter(<span class="string">'treatAsRandom'</span>,{});
            p.parse(varargin{:});

            f = classreg.regr.LinearFormula(formula);
            isMain= ~cellfun(@(x) (contains(x,<span class="string">'('</span>)|| contains(x,<span class="string">':'</span>)),f.TermNames);
            mainEffects  =f.TermNames(isMain)';
            isInteraction= cellfun(@(x) (contains(x,<span class="string">':'</span>)),f.TermNames);
            interactions = f.TermNames(isInteraction)';
                response = f.ResponseName;
            nrMainEffects =numel(mainEffects);
            nrInteractions = numel(interactions);
            allTerms = cat(2,mainEffects,interactions);
            nrAllTerms = nrMainEffects+nrInteractions;
</pre><h2 id="7">Setup sharing of priors as requested</h2><pre class="codeinput">            <span class="keyword">if</span> ischar(p.Results.sharedPriors)
                <span class="keyword">switch</span> upper(p.Results.sharedPriors)
                    <span class="keyword">case</span> <span class="string">'WITHIN'</span>
                        <span class="comment">% Share priors for each level of each factor, but not across factors</span>
                        sharedPriors = cell(1,nrAllTerms);
                        [sharedPriors{:}] = deal(allTerms{:});
                    <span class="keyword">case</span> <span class="string">'SINGLEG'</span>
                        sharedPriors = {allTerms};
                    <span class="keyword">case</span> {<span class="string">'NONE'</span>,<span class="string">''</span>}
                        sharedPriors ={};
                <span class="keyword">end</span>
            <span class="keyword">else</span>
                sharedPriors = p.Results.sharedPriors;
            <span class="keyword">end</span>
            sharedPriorIx = cell(1,numel(sharedPriors));
            [sharedPriorIx{:}] = deal([]);
</pre><h2 id="8">Construct the design matrix for the main effects</h2><pre class="codeinput">            designMatrix = cell(1,nrMainEffects +nrInteractions);
            <span class="keyword">for</span> i=1:nrMainEffects
                thisX = classreg.regr.modelutils.designmatrix(tbl,<span class="string">'model'</span>,<span class="string">'linear'</span>,<span class="string">'intercept'</span>,false,<span class="string">'DummyVarCoding'</span>,<span class="string">'full'</span>,<span class="string">'PredictorVars'</span>,mainEffects{i},<span class="string">'responseVar'</span>,<span class="string">''</span>);
                <span class="keyword">if</span> ismember(mainEffects{i},p.Results.treatAsRandom)
                    <span class="comment">% Random effect - Keep full dummy X</span>
                <span class="keyword">else</span>
                    <span class="comment">% Sum-to-zero contrasts that equates marginal priors across levels.</span>
                    thisX = o.zeroSumConstraint(thisX);
                <span class="keyword">end</span>
                designMatrix{i} =thisX; <span class="comment">% Store for later use</span>
            <span class="keyword">end</span>
</pre><h2 id="9">Construct the interaction parts of the design matrix for all requested interactions</h2><pre class="codeinput">            <span class="keyword">for</span> i=1:nrInteractions
                aName =extractBefore(interactions{i},<span class="string">':'</span>);
                bName = extractAfter(interactions{i},<span class="string">':'</span>);
                thisA = classreg.regr.modelutils.designmatrix(tbl,<span class="string">'model'</span>,<span class="string">'linear'</span>,<span class="string">'intercept'</span>,false,<span class="string">'DummyVarCoding'</span>,<span class="string">'full'</span>,<span class="string">'PredictorVars'</span>,aName,<span class="string">'responseVar'</span>,<span class="string">''</span>);
                thisB = classreg.regr.modelutils.designmatrix(tbl,<span class="string">'model'</span>,<span class="string">'linear'</span>,<span class="string">'intercept'</span>,false,<span class="string">'DummyVarCoding'</span>,<span class="string">'full'</span>,<span class="string">'PredictorVars'</span>,bName,<span class="string">'responseVar'</span>,<span class="string">''</span>);
                <span class="keyword">if</span> ~ismember(aName,p.Results.treatAsRandom)
                    thisA = o.zeroSumConstraint(thisA);
                <span class="keyword">end</span>
                <span class="keyword">if</span> ~ismember(bName,p.Results.treatAsRandom)
                    thisB = o.zeroSumConstraint(thisB);
                <span class="keyword">end</span>
                thisX = o.interaction(thisA,thisB);
                <span class="comment">%thisX = thisX -mean(thisX,2);</span>
                designMatrix{nrMainEffects+i} = thisX;
            <span class="keyword">end</span>
</pre><h2 id="10">Assign groups of effects to use the same prior on effect size.</h2><pre class="codeinput">            soFar  =0;
            <span class="keyword">if</span> isempty(sharedPriors)
                sharedPriorIx = {};
            <span class="keyword">else</span>
                <span class="keyword">for</span> i=1:numel(allTerms)
                    match = cellfun(@any,cellfun(@(x)(strcmp(allTerms{i},x)),sharedPriors,<span class="string">'UniformOutput'</span>,false));
                    <span class="keyword">if</span> ~any(match)
                        error([<span class="string">'Shared priors not defined for '</span> allTerms{i}]);
                    <span class="keyword">end</span>
                    nrInThisTerm  = size(designMatrix{i},2);
                    sharedPriorIx{match} = cat(2,sharedPriorIx{match},soFar+(1:nrInThisTerm));
                    soFar = soFar+nrInThisTerm;
                <span class="keyword">end</span>
            <span class="keyword">end</span>
</pre><h2 id="11">Call the anova function for the actual analysis</h2><pre class="codeinput">            bf10 = o.nWayAnova(tbl.(response),[designMatrix{:}],<span class="string">'sharedPriors'</span>,sharedPriorIx);


            <span class="keyword">if</span> nargout&gt;1
                <span class="comment">% Traditional</span>
                model  = fitlm(tbl,formula);
                aov = anova(model);
            <span class="keyword">end</span>
</pre><pre class="codeinput">        <span class="keyword">end</span>



    <span class="keyword">end</span>
</pre><pre class="codeoutput">
ans = 

  bayesFactor with properties:

          minG: 1.0000e-04
          maxG: 10000
         stepG: 0.0500
     nrSamples: 10000
    nDimsForMC: 3

</pre><h2 id="13">Internal computations.</h2><pre class="codeinput">    methods (Access = protected)

        <span class="keyword">function</span> v = mcIntegral(o,fun,prior,nrDims)
</pre><pre class="codeinput">            <span class="comment">% Monte Carlo integration</span>
            <span class="comment">%</span>
            <span class="comment">% INPUT</span>
            <span class="comment">% fun -  The function to integrate. This should be specified as a</span>
            <span class="comment">%       function_handle that takes a single input (g)</span>
            <span class="comment">% prior - the prior distribution of the g's. A function_handle.</span>
            <span class="comment">%</span>
            <span class="comment">% nrDims - The number of dimensions to integrate over. [1]</span>
            <span class="comment">% options - A struct with options.  []</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% v -  The value of the integral. (Typically the BF10).</span>
</pre><h2 id="15">Setup the PDF to do importance sampling</h2><pre class="codeinput">            gRange =  o.minG:o.stepG:o.maxG;
            pdf = prior(gRange);
            pdf = pdf./sum(pdf);
            <span class="comment">% Draw samples weighted by this prior.</span>
            g =nan(nrDims,o.nrSamples);
            <span class="keyword">for</span> d=1:nrDims
                g(d,:) = randsample(gRange,o.nrSamples,true,pdf);
            <span class="keyword">end</span>
</pre><h2 id="16">Evaluate the function at these g values</h2><pre class="codeinput">            bf10Samples = fun(g);
            pg = prod(prior(g),1);  <span class="comment">% Probability of each g combination</span>
            v = mean(bf10Samples./pg); <span class="comment">% Expectation value- = integral.</span>
</pre><pre class="codeinput">        <span class="keyword">end</span>


        <span class="keyword">function</span> bf10 = nWayAnova(o,y,X,varargin)
            <span class="comment">% ANOVA BF</span>
            <span class="comment">% y = data values</span>
            <span class="comment">% X = design matrix for ANOVA (indicator vars)  no constant term</span>
            <span class="comment">%</span>
            <span class="comment">% Parm/Value pairs</span>
            <span class="comment">% 'sharedPriors'  - Cell array of vectors indicating which effects (columns</span>
            <span class="comment">% of X) share the same prior. [{1:nrEffects}]: all effects share the same prior.</span>
            <span class="comment">%</span>
            <span class="comment">% BK 2018</span>
            nrEffects = size(X,2);

            p =inputParser;
            p.addParameter(<span class="string">'sharedPriors'</span>,{},@iscell); <span class="comment">% Which effects share a prior? A cell array with indices corresponding to columns of X</span>
            p.parse(varargin{:});

            <span class="keyword">if</span> isempty(p.Results.sharedPriors)
                sharedPriors = {1:nrEffects};
            <span class="keyword">else</span>
                sharedPriors = p.Results.sharedPriors;
            <span class="keyword">end</span>

            prior = @(g)(bayesFactor.scaledInverseChiPdf(g,1,1));
            integrand = @(varargin) (bayesFactor.rouderS(cat(1,varargin{:}),y,X,sharedPriors).*prod(prior(cat(1,varargin{:})),1));
            nrDims = numel(sharedPriors);
            <span class="keyword">if</span> nrDims&gt;= o.nDimsForMC
                <span class="comment">% Use MC Sampling to calculate the integral</span>
                bf10 = o.mcIntegral(integrand,prior,nrDims);
            <span class="keyword">else</span>
                <span class="keyword">switch</span> (nrDims)
                    <span class="keyword">case</span> 1
                        bf10 = integral(integrand,0,Inf);
                    <span class="keyword">case</span> 2
                        bf10 = integral2(integrand,0,Inf,0,Inf);
                    <span class="keyword">case</span> 3
                        bf10 = integral3(integrand,0,Inf,0,Inf,0,Inf);
                <span class="keyword">end</span>
            <span class="keyword">end</span>
        <span class="keyword">end</span>


    <span class="keyword">end</span>
</pre><h2 id="18">Helper functions</h2><pre class="codeinput">    methods (Static, Hidden)
        <span class="keyword">function</span> G = gMatrix(grouping,g)
            <span class="comment">% Generate a matrix in which each row corresponds to an effect, each column a value</span>
            <span class="comment">% that will be integrated over. The grouping cell array determines which of</span>
            <span class="comment">% the effects share a prior (i.e. levles of the same factor) and which have</span>
            <span class="comment">% their own.</span>
            <span class="comment">% grouping   - Cell array with vectors that contain effect indices (i.e.</span>
            <span class="comment">% columns of the design%matrix) that share a prior.</span>
            <span class="comment">% g  - The values for each of the priors. Each row is an independent prior,</span>
            <span class="comment">%               each column is a sample</span>
            <span class="comment">%</span>
            <span class="comment">% EXAMPLE</span>
            <span class="comment">% gMatrix({1 2],[3 4]},[0 0.1 0.2 0.3; 0.6 0.7 0.8 0.9])</span>
            <span class="comment">% g = [ 0 0.1 0.2 0.3;</span>
            <span class="comment">%       0 0.1 0.2 0.3;</span>
            <span class="comment">%       0.6 0.7 0.8 0.9;</span>
            <span class="comment">%       0.6 0.7 0.8 0.9]</span>


            nrEffects = sum(cellfun(@numel,grouping));
            assert(nrEffects&gt;0,<span class="string">'The number of groups must be at least one'</span>);
            nrValues = size(g,2);
            G = nan(nrEffects,nrValues);
            <span class="keyword">for</span> i=1:numel(grouping)
                G(grouping{i},:) = repmat(g(i,:),[numel(grouping{i}) 1]);
            <span class="keyword">end</span>
        <span class="keyword">end</span>

        <span class="keyword">function</span> value= rouderS(g,y,X,grouping)
            <span class="comment">% The S(g) function of Eq 9 in Rouder et al.</span>
            <span class="comment">% g = Matrix of g values, each row is an effect, each column is a value</span>
            <span class="comment">% that we're integrating over.</span>
            <span class="comment">% y = Data values</span>
            <span class="comment">% X = design matrix, without a constant term, with indicator variables only</span>

            g = bayesFactor.gMatrix(grouping,g);

            nrObservations = size(X,1);
            one = ones(nrObservations,1);
            P0 = 1./nrObservations*(one*one');
            yTilde = (eye(nrObservations)-P0)*y;
            XTilde = (eye(nrObservations)-P0)*X;
            nrPriorValues=size(g,2);
            value= nan(1,nrPriorValues);
            <span class="keyword">for</span> i=1:nrPriorValues
                <span class="keyword">if</span> all(g(:,i)==0)
                    value(i)=0;
                <span class="keyword">else</span>
                    G = diag(g(:,i));
                    invG = diag(1./g(:,i));
                    Vg = XTilde'*XTilde + invG;
                    yBar = one'*y/nrObservations;
                    preFactor= 1./(sqrt(det(G))*sqrt(det(Vg)));
                    numerator =    y'*y-nrObservations*yBar^2;
                    denominator = ((yTilde'*yTilde) -yTilde'*XTilde*(Vg\XTilde'*yTilde));
                    value(i)= preFactor*(numerator/denominator).^((nrObservations-1)/2);
                <span class="keyword">end</span>
            <span class="keyword">end</span>
        <span class="keyword">end</span>


        <span class="keyword">function</span> [Xa,Qa] = zeroSumConstraint(X)
</pre><pre class="codeinput">            <span class="comment">% Impose a zero-sum constraint on a dummy coded predictor matrix X</span>
            <span class="comment">% as in Rouder et al. 2012 . The goal is to make the model estimable</span>
            <span class="comment">% while equating marginal priors across levels.</span>
            <span class="comment">%</span>
            <span class="comment">% By default this is applied to all fixed effects.</span>
            <span class="comment">%</span>
            <span class="comment">% INPUT</span>
            <span class="comment">% X = Dummy coded predictor Matrix [nrObservations nrLevels].</span>
            <span class="comment">%       By passing a scalar, the function computes only the projection</span>
            <span class="comment">%       matrix (Qa) for a predictor matrix with that many effects.</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% Xa = Matrix with zero-sum constraint [nrObservations nrLevels-1]</span>
            <span class="comment">% Qa -  projection matrix (Xa = X*Qa).</span>
            <span class="comment">%</span>
            <span class="comment">% BK - 2018</span>

            <span class="keyword">if</span> isscalar(X)
                <span class="comment">% This is the number of effects</span>
                nrEffects = X;
            <span class="keyword">else</span>
                <span class="comment">%Design matrix was passed</span>
                nrEffects = size(X,2);
            <span class="keyword">end</span>
</pre><h2 id="20">Follow  Rouder et al. 2012</h2><pre class="codeinput">            Sigmaa =eye(nrEffects)- ones([nrEffects nrEffects])/nrEffects;
            [eigenVecs,ev]= eig(Sigmaa',<span class="string">'vector'</span>);
            [~,ix] = sort(ev,<span class="string">'desc'</span>);
            Qa = eigenVecs(:,ix(1:end-1));
            <span class="comment">%Iaminus1 = eye(nrEffects-1);</span>
            <span class="comment">%Sigmaa = Qa*Iaminus1*Qa';</span>
            <span class="keyword">if</span> isscalar(X)
                Xa =[];
            <span class="keyword">else</span>
                <span class="comment">% Transform design matrix</span>
                Xa = X*Qa;
            <span class="keyword">end</span>
</pre><pre class="codeinput">        <span class="keyword">end</span>

        <span class="keyword">function</span> interactions = allInteractions(factorNames)
            <span class="comment">% Given a cell array of factor names, create all pairwise combinations</span>
            <span class="comment">% of factors to represent interactions</span>
            <span class="comment">% INPUT</span>
            <span class="comment">% factorNames  - cell array of names</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% interactionNames - cell array of interaction names</span>
            <span class="comment">%</span>
            <span class="comment">% allInteractions({'a','b'}) -&gt; {'a:b'}</span>
            <span class="comment">%</span>
            <span class="comment">% BK  -Nov 2018</span>

            cntr=0;
            nrFactors = numel(factorNames);
            nrInteractions = nrFactors*(nrFactors-1)-1;
            interactions =cell(1,nrInteractions);
            <span class="keyword">for</span> i=1:nrFactors
                <span class="keyword">for</span> j=(i+1):nrFactors
                    cntr= cntr+1;
                    interactions{cntr} = [factorNames{i} <span class="string">':'</span> factorNames{j}];
                <span class="keyword">end</span>
            <span class="keyword">end</span>
        <span class="keyword">end</span>

        <span class="keyword">function</span> X = interaction(Xa,Xb)
            <span class="comment">% Create all interaction terms from two dummy coded design matrices.</span>
            <span class="comment">% (See Box II in Rouder et al. 2012)</span>
            <span class="comment">%</span>
            <span class="comment">% INPUT</span>
            <span class="comment">% Xa, Xb = [nrObservations nrA] and [nrObservations nrB]</span>
            <span class="comment">%           design matrices with matching number of observation (rows)</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% X = Dummy coded design matrix [nrObservations nrA*nrB]</span>
            <span class="comment">%</span>
            nA = size(Xa,2);
            nB = size(Xb,2);
            Xa = repmat(Xa,[1 nB]);
            Xb = repmat(Xb,[1 nA]);
            ix = (repmat(1:nA:nA*nB,[nA 1]) + repmat((0:nA-1)',[1 nB]))';
            Xa = Xa(:,ix(:));
            X= Xa.*Xb;

        <span class="keyword">end</span>


        <span class="keyword">function</span> y = inverseGammaPdf(x,alpha,beta)
            <span class="comment">% The inverse Gamma PDF.</span>
            <span class="comment">% INPUT</span>
            <span class="comment">% x  (&gt;0)</span>
            <span class="comment">% alpha - shape parameter</span>
            <span class="comment">% beta  - scale parameter</span>
            <span class="comment">%</span>
            <span class="comment">% BK - 2018</span>
            <span class="comment">%assert(all(x&gt;0),'The inverse gamma PDF is only defined for x&gt;0')</span>
            z = x&lt;0;
            y = zeros(size(z));
            y(~z) = (beta.^alpha)/gamma(alpha)*(1./x(~z)).^(alpha+1).*exp(-beta./x(~z));
        <span class="keyword">end</span>

        <span class="keyword">function</span> y = scaledInverseChiPdf(x,df,scale)
            <span class="comment">% The Scaled Inverse Chi-Squared Distribution.</span>
            <span class="comment">% INPUT</span>
            <span class="comment">% x = the parameter value</span>
            <span class="comment">% df = degrees of freedom</span>
            <span class="comment">% scale = scale (tau squared).</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% y = The probaility density</span>
            <span class="comment">%</span>
            <span class="comment">% BK - 2018</span>
            <span class="comment">%assert(all(x&gt;0),'The scaled inverse Chi-squared PDF is only defined for x&gt;0')</span>
            z = x&lt;0;
            y = zeros(size(z));
            <span class="keyword">if</span> nargin &lt;3
                scale =1; <span class="comment">% Default to scaled inverse Chi-squared.</span>
            <span class="keyword">end</span>
            y(~z) = bayesFactor.inverseGammaPdf(x(~z),df/2,df*scale/2);
        <span class="keyword">end</span>

    <span class="keyword">end</span>
</pre><h2 id="22">Public User interface</h2><pre class="codeinput">    methods (Static, Hidden=false)
        <span class="keyword">function</span> [bf10,p,CI,stats] = ttest2(X,Y,varargin)
            <span class="comment">% Calculates Bayes Factor for a two-sample t-test.</span>
            <span class="comment">% X - Sample 1</span>
            <span class="comment">% Y - Sample 2 (not necessarily of the same size)</span>
            <span class="comment">%</span>
            <span class="comment">% Optional Parm/Value pairs:</span>
            <span class="comment">% alpha - significance level for the frequentist test. [0.05]</span>
            <span class="comment">% tail - 'both','right', or 'left' for two or one-tailed tests [both]</span>
            <span class="comment">% scale - Scale of the Cauchy prior on the effect size  [sqrt(2)/2]</span>
            <span class="comment">% stats - A struct containing .tstat  , .df , .pvalue .tail and .N - This allows one to</span>
            <span class="comment">%               calculate BF10 directly from the results of a standard ttest2 output.</span>
            <span class="comment">%           Note, however, that .N should be adjusted to nX*nY/(nX+nY) ,</span>
            <span class="comment">%           and                 .df = nx+ny-2</span>
            <span class="comment">%           If you call this fuction with data (X, Y) this adjustment is</span>
            <span class="comment">%           done automatically.</span>
            <span class="comment">%</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% bf10 - The Bayes Factor for the hypothesis that the means of the samples are different</span>
            <span class="comment">% p     - p value of the frequentist hypothesis test</span>
            <span class="comment">% CI    - Confidence interval for the true mean of X</span>
            <span class="comment">% stats - Structure with .tstat, .df,resulting from the traditional test.</span>
            <span class="comment">%</span>
            <span class="comment">% Internally this code calls bf.ttest for the computation of Bayes Factors.</span>
            <span class="comment">%</span>
            <span class="comment">%</span>
            <span class="comment">% BK - Nov 2018</span>

            <span class="keyword">if</span> isnumeric(X)
                parms = varargin;
            <span class="keyword">else</span>
                <span class="comment">%Neither X nor Y specified (this must be a call with 'stats' specified</span>
                parms = cat(2,{X,Y,},varargin);
                X=[];Y=[];
            <span class="keyword">end</span>

            p=inputParser;
            p.addParameter(<span class="string">'alpha'</span>,0.05);
            p.addParameter(<span class="string">'tail'</span>,<span class="string">'both'</span>,@(x) (ischar(x)&amp;&amp; ismember(upper(x),{<span class="string">'BOTH'</span>,<span class="string">'RIGHT'</span>,<span class="string">'LEFT'</span>})));
            p.addParameter(<span class="string">'scale'</span>,sqrt(2)/2);
            p.addParameter(<span class="string">'stats'</span>,[],@isstruct);
            p.parse(parms{:});

            <span class="keyword">if</span> isempty(p.Results.stats)
                <span class="comment">% Calculate frequentist from the X and Y data</span>
                tail = p.Results.tail;
                [~,p,CI,stats] = ttest2(X,Y,<span class="string">'alpha'</span>,p.Results.alpha,<span class="string">'tail'</span>,tail);
                nX = numel(X);
                nY = numel(Y);
                statsForBf = stats;
                statsForBf.p = p;
                statsForBf.N = nX*nY/(nX+nY);
                statsForBf.df = nX+nY-2;
                statsForBf.tail = tail;
            <span class="keyword">else</span>
                <span class="comment">% User specified outcome of frequentist test (the builtin ttest), calculate BF from T and</span>
                <span class="comment">% df.</span>
                statsForBf = p.Results.stats;
            <span class="keyword">end</span>

            bf10 = bayesFactor.ttest(<span class="string">'stats'</span>,statsForBf);
        <span class="keyword">end</span>



        <span class="keyword">function</span> [bf10,pValue,CI,stats] = ttest(X,varargin)
            <span class="comment">% function [bf10,p,CI,stats] = ttest(X,Y,varargin)  - paired</span>
            <span class="comment">% function [bf10,p,CI,stats] = ttest(X,varargin)    - one sample</span>
            <span class="comment">% function [bf10,p,CI,stats] = ttest(X,M,varargin)   -one sample,non-zero mean</span>
            <span class="comment">%</span>
            <span class="comment">% Calculates Bayes Factor for a one-sample or paired T-test.</span>
            <span class="comment">%</span>
            <span class="comment">% X = single sample observations  (a column vector)</span>
            <span class="comment">% Y = paired observations (column vector) or a scalar mean to compare the samples in X to.</span>
            <span class="comment">%       {Defaults to 0]</span>
            <span class="comment">%</span>
            <span class="comment">% Optional Parm/Value pairs:</span>
            <span class="comment">% alpha - significance level for the frequentist test. [0.05]</span>
            <span class="comment">% tail - 'both','right', or 'left' for two or one-tailed tests [both]</span>
            <span class="comment">% scale - Scale of the Cauchy prior on the effect size  [sqrt(2)/2]</span>
            <span class="comment">% stats - A struct containing .tstat  , .df , .pvalue .tail and .N - This allows one to</span>
            <span class="comment">%               calculate BF10 directly from the results of a standard T-Test output.</span>
            <span class="comment">%</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% bf10 - The Bayes Factor for the hypothesis that the mean is different</span>
            <span class="comment">%           from zero</span>
            <span class="comment">% p - p value of the frequentist hypothesis test</span>
            <span class="comment">% CI    - Confidence interval for the true mean of X</span>
            <span class="comment">% stats - Structure with .tstat, .df,</span>
            <span class="comment">%</span>
            <span class="comment">% BK - Nov 2018</span>

            <span class="keyword">if</span> isnumeric(X)
                <span class="keyword">if</span> iseven(numel(varargin))
                    <span class="comment">% Only X specified</span>
                    Y = 0;
                    parms = varargin;
                <span class="keyword">else</span>
                    <span class="comment">% X and Y specified</span>
                    parms = varargin{2:end};
                    Y  =varargin{1};
                <span class="keyword">end</span>
            <span class="keyword">else</span>
                <span class="comment">%Neither X nor Y specified (must be a call with 'stats' specified</span>
                parms = cat(2,X,varargin);
                X=[];Y=[];
            <span class="keyword">end</span>
            p=inputParser;
            p.addParameter(<span class="string">'alpha'</span>,0.05);
            p.addParameter(<span class="string">'tail'</span>,<span class="string">'both'</span>,@(x) (ischar(x)&amp;&amp; ismember(upper(x),{<span class="string">'BOTH'</span>,<span class="string">'RIGHT'</span>,<span class="string">'LEFT'</span>})));
            p.addParameter(<span class="string">'scale'</span>,sqrt(2)/2);
            p.addParameter(<span class="string">'stats'</span>,[],@isstruct);
            p.parse(parms{:});


            <span class="keyword">if</span> isempty(p.Results.stats)
                <span class="comment">% Calculate frequentist from the X and Y data</span>
                tail = p.Results.tail;
                [~,pValue,CI,stats] = ttest(X,Y,<span class="string">'alpha'</span>,p.Results.alpha,<span class="string">'tail'</span>,tail);
                T = stats.tstat;
                df = stats.df;
                N = numel(X);
            <span class="keyword">else</span>
                <span class="comment">% User specified outcome of frequentist test (the builtin ttest), calculate BF from T and</span>
                <span class="comment">% df.</span>
                T = p.Results.stats.tstat;
                df = p.Results.stats.df;
                pValue = p.Results.stats.p;
                tail  = p.Results.stats.tail;
                N = p.Results.stats.N;
                CI = [NaN NaN];
            <span class="keyword">end</span>

            <span class="comment">% Use the formula from Rouder 2009</span>
            r = p.Results.scale;
            numerator = (1+T.^2/df).^(-(df+1)/2);
            fun  = @(g) ( ((1+N.*g.*r.^2).^-0.5) .* (1+T.^2./((1+N.*g.*r.^2).*df)).^(-(df+1)/2) .* (2*pi).^(-1/2) .* g.^(-3/2).*exp(-1./(2*g))  );
            <span class="comment">% Integrate over g</span>
            bf01 = numerator/integral(fun,0,inf);
            <span class="comment">% Return BF10</span>
            bf10 = 1./bf01;

            <span class="keyword">switch</span> (tail)
                <span class="keyword">case</span> <span class="string">'both'</span>
                    <span class="comment">% Nothing to do</span>
                <span class="keyword">case</span> {<span class="string">'left'</span>,<span class="string">'right'</span>}
                    <span class="comment">% Adjust the BF using hte p-value as an estimate for the posterior</span>
                    <span class="comment">% (Morey &amp; Wagenmakers, Stats and Prob Letts. 92 (2014):121-124.</span>
                    bf10 = 2*(1-p)*bf10;
            <span class="keyword">end</span>
        <span class="keyword">end</span>

        <span class="keyword">function</span> [bf10,p,pHat] = binotest(k,n,p)
            <span class="comment">% Bayes factor for binomial test with k successes, n trials and base probability p.</span>
            <span class="comment">% INPUT</span>
            <span class="comment">%  k - number of successes</span>
            <span class="comment">%  n - number of draws</span>
            <span class="comment">%  p - true binomial probabiliy</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% bf - Bayes Factor representing the evidence that this n/k</span>
            <span class="comment">% could result from random draws with p (BF&gt;1) or not (BF&lt;1)</span>
            <span class="comment">% p - p-value of a traditional test</span>
            <span class="comment">% pHat - esttimae of the binomial probablity</span>

            <span class="comment">% Code from Sam Schwarzkopf</span>
            F = @(q,k,n,p) nchoosek(n,k) .* q.^k .* (1-q).^(n-k);
            bf01 = (nchoosek(n,k) .* p.^k .* (1-p).^(n-k)) / integral(@(q) F(q,k,n,p),0,1);
            bf10 = 1/bf01;

            <span class="keyword">if</span> nargout&gt;1
                <span class="comment">% Traditional tests</span>
                pHat = binofit(k,n,0.05);
                p = 1-binocdf(k,n,p);
            <span class="keyword">end</span>

        <span class="keyword">end</span>


        <span class="keyword">function</span> [bf10,r,p] = corr(arg1,arg2)
            <span class="comment">% Calculate the Bayes Factor for Pearson correlation between two</span>
            <span class="comment">% variables.</span>
            <span class="comment">% INPUT</span>
            <span class="comment">% (x,y)  - two vectors of equal length.</span>
            <span class="comment">% OR</span>
            <span class="comment">% (r,n)  - the correlation and number of samples</span>
            <span class="comment">%</span>
            <span class="comment">% OUTPUT</span>
            <span class="comment">% bf10 = the Bayes Factor for the hypothesis that r is differnt</span>
            <span class="comment">%           from zero (two-tailed).</span>
            <span class="comment">% r - the correlation</span>
            <span class="comment">% p - the tradiational p-value based on Fisher-transformed</span>
            <span class="comment">%</span>
            <span class="keyword">if</span> isscalar(arg1) &amp;&amp; isscalar(arg2)
                r= arg1;
                n= arg2;
            <span class="keyword">else</span>
                x=arg1;y=arg2;
                [r,p] = corr(x,y,<span class="string">'type'</span>,<span class="string">'pearson'</span>);
                n=numel(x);
            <span class="keyword">end</span>

            <span class="comment">% Code from Sam Schwarzkopf</span>
            F = @(g,r,n) exp(((n-2)./2).*log(1+g)+(-(n-1)./2).*log(1+(1-r.^2).*g)+(-3./2).*log(g)+-n./(2.*g));
            bf10 = sqrt((n/2)) / gamma(1/2) * integral(@(g) F(g,r,n),0,Inf);

            <span class="keyword">if</span> nargout&gt;1
                <span class="comment">% Compute classical stats too</span>
                t = r.*sqrt((n-2)./(1-r.^2));
                p = 2*tcdf(-abs(t),n-2);
            <span class="keyword">end</span>
        <span class="keyword">end</span>
    <span class="keyword">end</span>
</pre><h2 id="23">Hide some of the handle class member functions for ease of use.</h2><pre class="codeinput">    methods (Hidden=true)
        <span class="keyword">function</span> notify(o)
        <span class="keyword">end</span>
        <span class="keyword">function</span> addlistener(o)
        <span class="keyword">end</span>
        <span class="keyword">function</span> findobj(o)
        <span class="keyword">end</span>
        <span class="keyword">function</span> findprop(o)
        <span class="keyword">end</span>
        <span class="keyword">function</span> listener(o)
        <span class="keyword">end</span>




    <span class="keyword">end</span>
</pre><pre class="codeinput"><span class="keyword">end</span>
</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2018b</a><br></p></div><!--
##### SOURCE BEGIN #####
classdef bayesFactor < handle
    % A class to perform Bayes Factor statistical analysis to quantify
    % evidnce in favor or against a hypothesis.
    % For background see:
    %
    % The mathemetical underpinning for these routines is provided in
    %
    %
    % Implementation notes:
    %  The class currently does not store data, only some default parameers
    %  that are used in different contexts.
    % BK - 2018
    
    properties (SetAccess = public, GetAccess =public)
        %% Default parameters for the Monte Carlo integration.
        minG = 0.0001;
        maxG = 10000;
        stepG = 0.05;
        nrSamples = 10000;
        nDimsForMC = 3; % If there are this many dimensions, use MC integration
        % 1 and 2D integration work fine with standard
        % integral.m but 3d is slow and higher not
        % possible.
    end
    
    %% Public acces functions - the main interface
    methods (Access=public)
        
        function o = bayesFactor
            % Constructor. Nothing to do.
            
        end
        
        function [bf10,model,aov] = linearMixedModel(o,tbl,formula,varargin)
            % Analyze table data with a linear mixed effects model.
            %
            % INPUT
            % tbl = The table with data.
            % formula = The linear (mixed) model using Wilcoxon notation.
            %           See LinearModel and LinearMixedModel in the stats
            %           toolbox for definition
            % Parm/Value pairs:
            % 'sharedPriors' - Which columns (i.e. factors) in the table should share a
            %                   their prior on their effect size. The default is that
            %                   all levels within a factor share a prior.
            %                   To share priors across factors, use
            %                      {'{'a','b'},{'c','d'}}   -> share priors for a and b
            %                       and, separately, for c and d.
            %                      {{'a','b','c','d'}} ->  share priors for all factors
            %                      (this is the 'single g' approach in Rouder.
            %                      Shortcuts:
            %                       'within' - share within a fixed effect factor, not across
            %                       'singleG' - share across all fixed effects.
            % 'interactions'    - Include interactions ('all') or not ('none'). Default
            %                       is  'none'.  Or specify a set {'a:b','c:d'}
            %
            % OUTPUT
            % bf10 - The Bayes Factor comparing the model to the model with intercept only.
            %       To compute BF for more refined hypotheses you compute
            %       a BF for the full model, and a restricted model and
            %       then take the ratio. See rouderFigures for examples.
            % model - A linear model or linear mixed model from the
            %           statistics toolbox
            % aov    - results of an ANOVA
            %
            % BK -2018
            
            p=inputParser;
            p.addParameter('interactions','none',@(x) (ischar(x) || iscell(x)));
            p.addParameter('sharedPriors','within',@(x) ischar(x) || (iscell(x) && iscell(x{1}))); % Cell containing cells with factors(columns) that share a prior.
            p.addParameter('treatAsRandom',{});
            p.parse(varargin{:});
            
            f = classreg.regr.LinearFormula(formula);
            isMain= ~cellfun(@(x) (contains(x,'(')|| contains(x,':')),f.TermNames);
            mainEffects  =f.TermNames(isMain)';
            isInteraction= cellfun(@(x) (contains(x,':')),f.TermNames);
            interactions = f.TermNames(isInteraction)';
                response = f.ResponseName;
            nrMainEffects =numel(mainEffects);
            nrInteractions = numel(interactions);
            allTerms = cat(2,mainEffects,interactions);
            nrAllTerms = nrMainEffects+nrInteractions;
            
            %% Setup sharing of priors as requested
            if ischar(p.Results.sharedPriors)
                switch upper(p.Results.sharedPriors)
                    case 'WITHIN'
                        % Share priors for each level of each factor, but not across factors
                        sharedPriors = cell(1,nrAllTerms);
                        [sharedPriors{:}] = deal(allTerms{:});
                    case 'SINGLEG'
                        sharedPriors = {allTerms};
                    case {'NONE',''}
                        sharedPriors ={};
                end
            else
                sharedPriors = p.Results.sharedPriors;
            end
            sharedPriorIx = cell(1,numel(sharedPriors));
            [sharedPriorIx{:}] = deal([]);
            
            %% Construct the design matrix for the main effects
            designMatrix = cell(1,nrMainEffects +nrInteractions);
            for i=1:nrMainEffects
                thisX = classreg.regr.modelutils.designmatrix(tbl,'model','linear','intercept',false,'DummyVarCoding','full','PredictorVars',mainEffects{i},'responseVar','');
                if ismember(mainEffects{i},p.Results.treatAsRandom)
                    % Random effect - Keep full dummy X
                else
                    % Sum-to-zero contrasts that equates marginal priors across levels.
                    thisX = o.zeroSumConstraint(thisX);
                end
                designMatrix{i} =thisX; % Store for later use
            end
            
            %% Construct the interaction parts of the design matrix for all requested interactions
            for i=1:nrInteractions
                aName =extractBefore(interactions{i},':');
                bName = extractAfter(interactions{i},':');
                thisA = classreg.regr.modelutils.designmatrix(tbl,'model','linear','intercept',false,'DummyVarCoding','full','PredictorVars',aName,'responseVar','');
                thisB = classreg.regr.modelutils.designmatrix(tbl,'model','linear','intercept',false,'DummyVarCoding','full','PredictorVars',bName,'responseVar','');
                if ~ismember(aName,p.Results.treatAsRandom)
                    thisA = o.zeroSumConstraint(thisA);
                end
                if ~ismember(bName,p.Results.treatAsRandom)
                    thisB = o.zeroSumConstraint(thisB);
                end
                thisX = o.interaction(thisA,thisB);
                %thisX = thisX -mean(thisX,2);
                designMatrix{nrMainEffects+i} = thisX;
            end
            
            
            %% Assign groups of effects to use the same prior on effect size.
            soFar  =0;
            if isempty(sharedPriors)
                sharedPriorIx = {};
            else
                for i=1:numel(allTerms)
                    match = cellfun(@any,cellfun(@(x)(strcmp(allTerms{i},x)),sharedPriors,'UniformOutput',false));
                    if ~any(match)
                        error(['Shared priors not defined for ' allTerms{i}]);
                    end
                    nrInThisTerm  = size(designMatrix{i},2);
                    sharedPriorIx{match} = cat(2,sharedPriorIx{match},soFar+(1:nrInThisTerm));
                    soFar = soFar+nrInThisTerm;
                end
            end
            %% Call the anova function for the actual analysis
            bf10 = o.nWayAnova(tbl.(response),[designMatrix{:}],'sharedPriors',sharedPriorIx);
            
            
            if nargout>1
                % Traditional
                model  = fitlm(tbl,formula);
                aov = anova(model);
            end
        end
        
        
        
    end
    
    %% Internal computations.
    methods (Access = protected)
        
        function v = mcIntegral(o,fun,prior,nrDims)
            % Monte Carlo integration
            %
            % INPUT
            % fun -  The function to integrate. This should be specified as a
            %       function_handle that takes a single input (g)
            % prior - the prior distribution of the g's. A function_handle.
            %
            % nrDims - The number of dimensions to integrate over. [1]
            % options - A struct with options.  []
            % OUTPUT
            % v -  The value of the integral. (Typically the BF10).
            
            
            %% Setup the PDF to do importance sampling
            gRange =  o.minG:o.stepG:o.maxG;
            pdf = prior(gRange);
            pdf = pdf./sum(pdf);
            % Draw samples weighted by this prior.
            g =nan(nrDims,o.nrSamples);
            for d=1:nrDims
                g(d,:) = randsample(gRange,o.nrSamples,true,pdf);
            end
            %% Evaluate the function at these g values
            bf10Samples = fun(g);
            pg = prod(prior(g),1);  % Probability of each g combination
            v = mean(bf10Samples./pg); % Expectation value- = integral.
        end
        
        
        function bf10 = nWayAnova(o,y,X,varargin)
            % ANOVA BF
            % y = data values
            % X = design matrix for ANOVA (indicator vars)  no constant term
            %
            % Parm/Value pairs
            % 'sharedPriors'  - Cell array of vectors indicating which effects (columns
            % of X) share the same prior. [{1:nrEffects}]: all effects share the same prior.
            %
            % BK 2018
            nrEffects = size(X,2);
            
            p =inputParser;
            p.addParameter('sharedPriors',{},@iscell); % Which effects share a prior? A cell array with indices corresponding to columns of X
            p.parse(varargin{:});
            
            if isempty(p.Results.sharedPriors)
                sharedPriors = {1:nrEffects};
            else
                sharedPriors = p.Results.sharedPriors;
            end
            
            prior = @(g)(bayesFactor.scaledInverseChiPdf(g,1,1));
            integrand = @(varargin) (bayesFactor.rouderS(cat(1,varargin{:}),y,X,sharedPriors).*prod(prior(cat(1,varargin{:})),1));
            nrDims = numel(sharedPriors);
            if nrDims>= o.nDimsForMC
                % Use MC Sampling to calculate the integral
                bf10 = o.mcIntegral(integrand,prior,nrDims);
            else
                switch (nrDims)
                    case 1
                        bf10 = integral(integrand,0,Inf);
                    case 2
                        bf10 = integral2(integrand,0,Inf,0,Inf);
                    case 3
                        bf10 = integral3(integrand,0,Inf,0,Inf,0,Inf);
                end
            end
        end
        
        
    end
    
    %% Helper functions
    methods (Static, Hidden)
        function G = gMatrix(grouping,g)
            % Generate a matrix in which each row corresponds to an effect, each column a value
            % that will be integrated over. The grouping cell array determines which of
            % the effects share a prior (i.e. levles of the same factor) and which have
            % their own.
            % grouping   - Cell array with vectors that contain effect indices (i.e.
            % columns of the design%matrix) that share a prior.
            % g  - The values for each of the priors. Each row is an independent prior,
            %               each column is a sample
            %
            % EXAMPLE
            % gMatrix({1 2],[3 4]},[0 0.1 0.2 0.3; 0.6 0.7 0.8 0.9])
            % g = [ 0 0.1 0.2 0.3;
            %       0 0.1 0.2 0.3;
            %       0.6 0.7 0.8 0.9;
            %       0.6 0.7 0.8 0.9]
            
            
            nrEffects = sum(cellfun(@numel,grouping));
            assert(nrEffects>0,'The number of groups must be at least one');
            nrValues = size(g,2);
            G = nan(nrEffects,nrValues);
            for i=1:numel(grouping)
                G(grouping{i},:) = repmat(g(i,:),[numel(grouping{i}) 1]);
            end
        end
        
        function value= rouderS(g,y,X,grouping)
            % The S(g) function of Eq 9 in Rouder et al.
            % g = Matrix of g values, each row is an effect, each column is a value
            % that we're integrating over.
            % y = Data values
            % X = design matrix, without a constant term, with indicator variables only
            
            g = bayesFactor.gMatrix(grouping,g);
            
            nrObservations = size(X,1);
            one = ones(nrObservations,1);
            P0 = 1./nrObservations*(one*one');
            yTilde = (eye(nrObservations)-P0)*y;
            XTilde = (eye(nrObservations)-P0)*X;
            nrPriorValues=size(g,2);
            value= nan(1,nrPriorValues);
            for i=1:nrPriorValues
                if all(g(:,i)==0)
                    value(i)=0;
                else
                    G = diag(g(:,i));
                    invG = diag(1./g(:,i));
                    Vg = XTilde'*XTilde + invG;
                    yBar = one'*y/nrObservations;
                    preFactor= 1./(sqrt(det(G))*sqrt(det(Vg)));
                    numerator =    y'*y-nrObservations*yBar^2;
                    denominator = ((yTilde'*yTilde) -yTilde'*XTilde*(Vg\XTilde'*yTilde));
                    value(i)= preFactor*(numerator/denominator).^((nrObservations-1)/2);
                end
            end
        end
        
        
        function [Xa,Qa] = zeroSumConstraint(X)
            % Impose a zero-sum constraint on a dummy coded predictor matrix X
            % as in Rouder et al. 2012 . The goal is to make the model estimable
            % while equating marginal priors across levels.
            %
            % By default this is applied to all fixed effects.
            %
            % INPUT
            % X = Dummy coded predictor Matrix [nrObservations nrLevels].
            %       By passing a scalar, the function computes only the projection
            %       matrix (Qa) for a predictor matrix with that many effects.
            % OUTPUT
            % Xa = Matrix with zero-sum constraint [nrObservations nrLevels-1]
            % Qa -  projection matrix (Xa = X*Qa).
            %
            % BK - 2018
            
            if isscalar(X)
                % This is the number of effects
                nrEffects = X;
            else
                %Design matrix was passed
                nrEffects = size(X,2);
            end
            
            %% Follow  Rouder et al. 2012
            Sigmaa =eye(nrEffects)- ones([nrEffects nrEffects])/nrEffects;
            [eigenVecs,ev]= eig(Sigmaa','vector');
            [~,ix] = sort(ev,'desc');
            Qa = eigenVecs(:,ix(1:end-1));
            %Iaminus1 = eye(nrEffects-1);
            %Sigmaa = Qa*Iaminus1*Qa';
            if isscalar(X)
                Xa =[];
            else
                % Transform design matrix
                Xa = X*Qa;
            end
            
        end
        
        function interactions = allInteractions(factorNames)
            % Given a cell array of factor names, create all pairwise combinations
            % of factors to represent interactions
            % INPUT
            % factorNames  - cell array of names
            % OUTPUT
            % interactionNames - cell array of interaction names
            %
            % allInteractions({'a','b'}) -> {'a:b'}
            %
            % BK  -Nov 2018
            
            cntr=0;
            nrFactors = numel(factorNames);
            nrInteractions = nrFactors*(nrFactors-1)-1;
            interactions =cell(1,nrInteractions);
            for i=1:nrFactors
                for j=(i+1):nrFactors
                    cntr= cntr+1;
                    interactions{cntr} = [factorNames{i} ':' factorNames{j}];
                end
            end
        end
        
        function X = interaction(Xa,Xb)
            % Create all interaction terms from two dummy coded design matrices.
            % (See Box II in Rouder et al. 2012)
            %
            % INPUT
            % Xa, Xb = [nrObservations nrA] and [nrObservations nrB]
            %           design matrices with matching number of observation (rows)
            % OUTPUT
            % X = Dummy coded design matrix [nrObservations nrA*nrB]
            %
            nA = size(Xa,2);
            nB = size(Xb,2);
            Xa = repmat(Xa,[1 nB]);
            Xb = repmat(Xb,[1 nA]);
            ix = (repmat(1:nA:nA*nB,[nA 1]) + repmat((0:nA-1)',[1 nB]))';
            Xa = Xa(:,ix(:));
            X= Xa.*Xb;
            
        end
        
        
        function y = inverseGammaPdf(x,alpha,beta)
            % The inverse Gamma PDF.
            % INPUT
            % x  (>0)
            % alpha - shape parameter
            % beta  - scale parameter
            %
            % BK - 2018
            %assert(all(x>0),'The inverse gamma PDF is only defined for x>0')
            z = x<0;
            y = zeros(size(z));
            y(~z) = (beta.^alpha)/gamma(alpha)*(1./x(~z)).^(alpha+1).*exp(-beta./x(~z));
        end
        
        function y = scaledInverseChiPdf(x,df,scale)
            % The Scaled Inverse Chi-Squared Distribution.
            % INPUT
            % x = the parameter value
            % df = degrees of freedom
            % scale = scale (tau squared).
            % OUTPUT
            % y = The probaility density
            %
            % BK - 2018
            %assert(all(x>0),'The scaled inverse Chi-squared PDF is only defined for x>0')
            z = x<0;
            y = zeros(size(z));
            if nargin <3
                scale =1; % Default to scaled inverse Chi-squared.
            end
            y(~z) = bayesFactor.inverseGammaPdf(x(~z),df/2,df*scale/2);
        end
        
    end
    
    %% Public User interface
    methods (Static, Hidden=false)
        function [bf10,p,CI,stats] = ttest2(X,Y,varargin)
            % Calculates Bayes Factor for a two-sample t-test.
            % X - Sample 1
            % Y - Sample 2 (not necessarily of the same size)
            %
            % Optional Parm/Value pairs:
            % alpha - significance level for the frequentist test. [0.05]
            % tail - 'both','right', or 'left' for two or one-tailed tests [both]
            % scale - Scale of the Cauchy prior on the effect size  [sqrt(2)/2]
            % stats - A struct containing .tstat  , .df , .pvalue .tail and .N - This allows one to
            %               calculate BF10 directly from the results of a standard ttest2 output.
            %           Note, however, that .N should be adjusted to nX*nY/(nX+nY) ,
            %           and                 .df = nx+ny-2
            %           If you call this fuction with data (X, Y) this adjustment is
            %           done automatically.
            %
            % OUTPUT
            % bf10 - The Bayes Factor for the hypothesis that the means of the samples are different
            % p     - p value of the frequentist hypothesis test
            % CI    - Confidence interval for the true mean of X
            % stats - Structure with .tstat, .df,resulting from the traditional test.
            %
            % Internally this code calls bf.ttest for the computation of Bayes Factors.
            %
            %
            % BK - Nov 2018
            
            if isnumeric(X)
                parms = varargin;
            else
                %Neither X nor Y specified (this must be a call with 'stats' specified
                parms = cat(2,{X,Y,},varargin);
                X=[];Y=[];
            end
            
            p=inputParser;
            p.addParameter('alpha',0.05);
            p.addParameter('tail','both',@(x) (ischar(x)&& ismember(upper(x),{'BOTH','RIGHT','LEFT'})));
            p.addParameter('scale',sqrt(2)/2);
            p.addParameter('stats',[],@isstruct);
            p.parse(parms{:});
            
            if isempty(p.Results.stats)
                % Calculate frequentist from the X and Y data
                tail = p.Results.tail;
                [~,p,CI,stats] = ttest2(X,Y,'alpha',p.Results.alpha,'tail',tail);
                nX = numel(X);
                nY = numel(Y);
                statsForBf = stats;
                statsForBf.p = p;
                statsForBf.N = nX*nY/(nX+nY);
                statsForBf.df = nX+nY-2;
                statsForBf.tail = tail;
            else
                % User specified outcome of frequentist test (the builtin ttest), calculate BF from T and
                % df.
                statsForBf = p.Results.stats;
            end
            
            bf10 = bayesFactor.ttest('stats',statsForBf);
        end
        
        
        
        function [bf10,pValue,CI,stats] = ttest(X,varargin)
            % function [bf10,p,CI,stats] = ttest(X,Y,varargin)  - paired
            % function [bf10,p,CI,stats] = ttest(X,varargin)    - one sample
            % function [bf10,p,CI,stats] = ttest(X,M,varargin)   -one sample,non-zero mean
            %
            % Calculates Bayes Factor for a one-sample or paired T-test.
            %
            % X = single sample observations  (a column vector)
            % Y = paired observations (column vector) or a scalar mean to compare the samples in X to.
            %       {Defaults to 0]
            %
            % Optional Parm/Value pairs:
            % alpha - significance level for the frequentist test. [0.05]
            % tail - 'both','right', or 'left' for two or one-tailed tests [both]
            % scale - Scale of the Cauchy prior on the effect size  [sqrt(2)/2]
            % stats - A struct containing .tstat  , .df , .pvalue .tail and .N - This allows one to
            %               calculate BF10 directly from the results of a standard T-Test output.
            %
            % OUTPUT
            % bf10 - The Bayes Factor for the hypothesis that the mean is different
            %           from zero
            % p - p value of the frequentist hypothesis test
            % CI    - Confidence interval for the true mean of X
            % stats - Structure with .tstat, .df,
            %
            % BK - Nov 2018
            
            if isnumeric(X)
                if iseven(numel(varargin))
                    % Only X specified
                    Y = 0;
                    parms = varargin;
                else
                    % X and Y specified
                    parms = varargin{2:end};
                    Y  =varargin{1};
                end
            else
                %Neither X nor Y specified (must be a call with 'stats' specified
                parms = cat(2,X,varargin);
                X=[];Y=[];
            end
            p=inputParser;
            p.addParameter('alpha',0.05);
            p.addParameter('tail','both',@(x) (ischar(x)&& ismember(upper(x),{'BOTH','RIGHT','LEFT'})));
            p.addParameter('scale',sqrt(2)/2);
            p.addParameter('stats',[],@isstruct);
            p.parse(parms{:});
            
            
            if isempty(p.Results.stats)
                % Calculate frequentist from the X and Y data
                tail = p.Results.tail;
                [~,pValue,CI,stats] = ttest(X,Y,'alpha',p.Results.alpha,'tail',tail);
                T = stats.tstat;
                df = stats.df;
                N = numel(X);
            else
                % User specified outcome of frequentist test (the builtin ttest), calculate BF from T and
                % df.
                T = p.Results.stats.tstat;
                df = p.Results.stats.df;
                pValue = p.Results.stats.p;
                tail  = p.Results.stats.tail;
                N = p.Results.stats.N;
                CI = [NaN NaN];
            end
            
            % Use the formula from Rouder 2009
            r = p.Results.scale;
            numerator = (1+T.^2/df).^(-(df+1)/2);
            fun  = @(g) ( ((1+N.*g.*r.^2).^-0.5) .* (1+T.^2./((1+N.*g.*r.^2).*df)).^(-(df+1)/2) .* (2*pi).^(-1/2) .* g.^(-3/2).*exp(-1./(2*g))  );
            % Integrate over g
            bf01 = numerator/integral(fun,0,inf);
            % Return BF10
            bf10 = 1./bf01;
            
            switch (tail)
                case 'both'
                    % Nothing to do
                case {'left','right'}
                    % Adjust the BF using hte p-value as an estimate for the posterior
                    % (Morey & Wagenmakers, Stats and Prob Letts. 92 (2014):121-124.
                    bf10 = 2*(1-p)*bf10;
            end
        end
        
        function [bf10,p,pHat] = binotest(k,n,p)
            % Bayes factor for binomial test with k successes, n trials and base probability p.
            % INPUT
            %  k - number of successes
            %  n - number of draws
            %  p - true binomial probabiliy
            % OUTPUT
            % bf - Bayes Factor representing the evidence that this n/k
            % could result from random draws with p (BF>1) or not (BF<1)
            % p - p-value of a traditional test
            % pHat - esttimae of the binomial probablity
            
            % Code from Sam Schwarzkopf
            F = @(q,k,n,p) nchoosek(n,k) .* q.^k .* (1-q).^(n-k);
            bf01 = (nchoosek(n,k) .* p.^k .* (1-p).^(n-k)) / integral(@(q) F(q,k,n,p),0,1);
            bf10 = 1/bf01;
            
            if nargout>1
                % Traditional tests
                pHat = binofit(k,n,0.05);
                p = 1-binocdf(k,n,p);
            end
            
        end
        
        
        function [bf10,r,p] = corr(arg1,arg2)
            % Calculate the Bayes Factor for Pearson correlation between two
            % variables.
            % INPUT
            % (x,y)  - two vectors of equal length.
            % OR
            % (r,n)  - the correlation and number of samples
            %
            % OUTPUT
            % bf10 = the Bayes Factor for the hypothesis that r is differnt
            %           from zero (two-tailed).
            % r - the correlation
            % p - the tradiational p-value based on Fisher-transformed
            %
            if isscalar(arg1) && isscalar(arg2)
                r= arg1;
                n= arg2;
            else
                x=arg1;y=arg2;
                [r,p] = corr(x,y,'type','pearson');
                n=numel(x);
            end
            
            % Code from Sam Schwarzkopf
            F = @(g,r,n) exp(((n-2)./2).*log(1+g)+(-(n-1)./2).*log(1+(1-r.^2).*g)+(-3./2).*log(g)+-n./(2.*g));
            bf10 = sqrt((n/2)) / gamma(1/2) * integral(@(g) F(g,r,n),0,Inf);
            
            if nargout>1
                % Compute classical stats too
                t = r.*sqrt((n-2)./(1-r.^2));
                p = 2*tcdf(-abs(t),n-2);
            end
        end
    end
    
    %% Hide some of the handle class member functions for ease of use.
    methods (Hidden=true)
        function notify(o)
        end
        function addlistener(o)
        end
        function findobj(o)
        end
        function findprop(o)
        end
        function listener(o)
        end
        
        
        
        
    end
end
##### SOURCE END #####
--></body></html>